kind: Workflow
metadata:
  generateName: test-fileshare
spec:
  entrypoint: pipeline
  templates:
  - name: pipeline
    inputs:
      artifacts:
        - name: data-test
          path: artifact_test/data_test.txt
          s3:
            endpoint: s3.amazonaws.com
            bucket: tiny-torch
            key: artifact_test/data_test.txt.tgz
            accessKeySecret:
              name: my-aws-s3-credentials
              key: accessKey
            secretKeySecret:
              name: my-aws-s3-credentials
              key: secretKey
    dag:
      tasks:
        - name: fileshare-write
          template: fileshare-write-template
        - name: fileshare-read
          template: fileshare-read-template
          dependencies:
            - fileshare-write
          arguments:
            artifacts:
              - name: data-test
                from: '{{tasks.fileshare-write.outputs.artifacts.data-test}}'
  - name: fileshare-write-template
    container:
      image: ericdatakelly/nebari-workflow2
      command: ['python', '/tiny-torch/file_share_test_write.py']
    outputs:
      artifacts:
        - name: data-test
          path: 'artifact_test/data_test.txt'
  - name: fileshare-read-template
    container:
      image: ericdatakelly/nebari-workflow2
      command: ['python', '/tiny-torch/file_share_test_read.py']
